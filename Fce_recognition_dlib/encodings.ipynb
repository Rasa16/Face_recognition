{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "encodings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tmxOOuAjBDOLjvGOS3xqKJe8LVFR12MO",
      "authorship_tag": "ABX9TyNgB+Hly5DYYIJSNZPYhhd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rasa16/Face_recognition/blob/master/encodings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBw_Wzi9T4mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "ff656830-1b2a-407e-d479-35113c39e816"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.4)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=25fd5962a58922a83237fad2f9eff1d8c70ee8823e6f0f133c2743e620b8a6e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E6DfBLigV8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils import paths\n",
        "import face_recognition\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5MRQhEg0PX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d8700de-6626-439b-9fce-fcf110690db0"
      },
      "source": [
        "# grab the paths to the input images in our dataset\n",
        "print(\"[INFO] quantifying faces...\")\n",
        "imagePaths = list(paths.list_images(\"/content/drive/My Drive/Face_recognition_own/My family\"))\n",
        "\n",
        "# initialize the list of known encodings and known names\n",
        "knownEncodings = []\n",
        "knownNames = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] quantifying faces...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsB-ZxpqhR1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e25c2c12-1732-4470-d943-e5ebb6de0c39"
      },
      "source": [
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# extract the person name from the image path\n",
        "\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "\t\tlen(imagePaths)))\n",
        "\tname = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image and convert it from BGR (OpenCV ordering)\n",
        "\t# to dlib ordering (RGB)\n",
        "\timage = cv2.imread(imagePath)\n",
        "\trgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "\t# detect the (x, y)-coordinates of the bounding boxes\n",
        "\t# corresponding to each face in the input image\n",
        "\tboxes = face_recognition.face_locations(rgb,\n",
        "\t\tmodel=\"hog\")\n",
        "\n",
        "\t# compute the facial embedding for the face\n",
        "\tencodings = face_recognition.face_encodings(rgb, boxes)\n",
        "\n",
        "\t# loop over the encodings\n",
        "\tfor encoding in encodings:\n",
        "\t\t# add each encoding + name to our set of known names and\n",
        "\t\t# encodings\n",
        "\t\tknownEncodings.append(encoding)\n",
        "\t\tknownNames.append(name)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] processing image 1/136\n",
            "[INFO] processing image 2/136\n",
            "[INFO] processing image 3/136\n",
            "[INFO] processing image 4/136\n",
            "[INFO] processing image 5/136\n",
            "[INFO] processing image 6/136\n",
            "[INFO] processing image 7/136\n",
            "[INFO] processing image 8/136\n",
            "[INFO] processing image 9/136\n",
            "[INFO] processing image 10/136\n",
            "[INFO] processing image 11/136\n",
            "[INFO] processing image 12/136\n",
            "[INFO] processing image 13/136\n",
            "[INFO] processing image 14/136\n",
            "[INFO] processing image 15/136\n",
            "[INFO] processing image 16/136\n",
            "[INFO] processing image 17/136\n",
            "[INFO] processing image 18/136\n",
            "[INFO] processing image 19/136\n",
            "[INFO] processing image 20/136\n",
            "[INFO] processing image 21/136\n",
            "[INFO] processing image 22/136\n",
            "[INFO] processing image 23/136\n",
            "[INFO] processing image 24/136\n",
            "[INFO] processing image 25/136\n",
            "[INFO] processing image 26/136\n",
            "[INFO] processing image 27/136\n",
            "[INFO] processing image 28/136\n",
            "[INFO] processing image 29/136\n",
            "[INFO] processing image 30/136\n",
            "[INFO] processing image 31/136\n",
            "[INFO] processing image 32/136\n",
            "[INFO] processing image 33/136\n",
            "[INFO] processing image 34/136\n",
            "[INFO] processing image 35/136\n",
            "[INFO] processing image 36/136\n",
            "[INFO] processing image 37/136\n",
            "[INFO] processing image 38/136\n",
            "[INFO] processing image 39/136\n",
            "[INFO] processing image 40/136\n",
            "[INFO] processing image 41/136\n",
            "[INFO] processing image 42/136\n",
            "[INFO] processing image 43/136\n",
            "[INFO] processing image 44/136\n",
            "[INFO] processing image 45/136\n",
            "[INFO] processing image 46/136\n",
            "[INFO] processing image 47/136\n",
            "[INFO] processing image 48/136\n",
            "[INFO] processing image 49/136\n",
            "[INFO] processing image 50/136\n",
            "[INFO] processing image 51/136\n",
            "[INFO] processing image 52/136\n",
            "[INFO] processing image 53/136\n",
            "[INFO] processing image 54/136\n",
            "[INFO] processing image 55/136\n",
            "[INFO] processing image 56/136\n",
            "[INFO] processing image 57/136\n",
            "[INFO] processing image 58/136\n",
            "[INFO] processing image 59/136\n",
            "[INFO] processing image 60/136\n",
            "[INFO] processing image 61/136\n",
            "[INFO] processing image 62/136\n",
            "[INFO] processing image 63/136\n",
            "[INFO] processing image 64/136\n",
            "[INFO] processing image 65/136\n",
            "[INFO] processing image 66/136\n",
            "[INFO] processing image 67/136\n",
            "[INFO] processing image 68/136\n",
            "[INFO] processing image 69/136\n",
            "[INFO] processing image 70/136\n",
            "[INFO] processing image 71/136\n",
            "[INFO] processing image 72/136\n",
            "[INFO] processing image 73/136\n",
            "[INFO] processing image 74/136\n",
            "[INFO] processing image 75/136\n",
            "[INFO] processing image 76/136\n",
            "[INFO] processing image 77/136\n",
            "[INFO] processing image 78/136\n",
            "[INFO] processing image 79/136\n",
            "[INFO] processing image 80/136\n",
            "[INFO] processing image 81/136\n",
            "[INFO] processing image 82/136\n",
            "[INFO] processing image 83/136\n",
            "[INFO] processing image 84/136\n",
            "[INFO] processing image 85/136\n",
            "[INFO] processing image 86/136\n",
            "[INFO] processing image 87/136\n",
            "[INFO] processing image 88/136\n",
            "[INFO] processing image 89/136\n",
            "[INFO] processing image 90/136\n",
            "[INFO] processing image 91/136\n",
            "[INFO] processing image 92/136\n",
            "[INFO] processing image 93/136\n",
            "[INFO] processing image 94/136\n",
            "[INFO] processing image 95/136\n",
            "[INFO] processing image 96/136\n",
            "[INFO] processing image 97/136\n",
            "[INFO] processing image 98/136\n",
            "[INFO] processing image 99/136\n",
            "[INFO] processing image 100/136\n",
            "[INFO] processing image 101/136\n",
            "[INFO] processing image 102/136\n",
            "[INFO] processing image 103/136\n",
            "[INFO] processing image 104/136\n",
            "[INFO] processing image 105/136\n",
            "[INFO] processing image 106/136\n",
            "[INFO] processing image 107/136\n",
            "[INFO] processing image 108/136\n",
            "[INFO] processing image 109/136\n",
            "[INFO] processing image 110/136\n",
            "[INFO] processing image 111/136\n",
            "[INFO] processing image 112/136\n",
            "[INFO] processing image 113/136\n",
            "[INFO] processing image 114/136\n",
            "[INFO] processing image 115/136\n",
            "[INFO] processing image 116/136\n",
            "[INFO] processing image 117/136\n",
            "[INFO] processing image 118/136\n",
            "[INFO] processing image 119/136\n",
            "[INFO] processing image 120/136\n",
            "[INFO] processing image 121/136\n",
            "[INFO] processing image 122/136\n",
            "[INFO] processing image 123/136\n",
            "[INFO] processing image 124/136\n",
            "[INFO] processing image 125/136\n",
            "[INFO] processing image 126/136\n",
            "[INFO] processing image 127/136\n",
            "[INFO] processing image 128/136\n",
            "[INFO] processing image 129/136\n",
            "[INFO] processing image 130/136\n",
            "[INFO] processing image 131/136\n",
            "[INFO] processing image 132/136\n",
            "[INFO] processing image 133/136\n",
            "[INFO] processing image 134/136\n",
            "[INFO] processing image 135/136\n",
            "[INFO] processing image 136/136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gWGIpAKh6yE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69b9dbaf-105b-46af-f558-561849530f62"
      },
      "source": [
        "# dump the facial encodings + names to disk\n",
        "print(\"[INFO] serializing encodings...\")\n",
        "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
        "f = open(\"/content/drive/My Drive/Face_recognition_own/my_family_encodings.pickle\", \"wb\")\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] serializing encodings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsZxHUe4l6s2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6195c2a7-762d-4f55-adb2-d2661eb623e9"
      },
      "source": [
        "print(knownNames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Ajay', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Rahul', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Sulekha', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima', 'Ashima']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRlqj6WfmEhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
